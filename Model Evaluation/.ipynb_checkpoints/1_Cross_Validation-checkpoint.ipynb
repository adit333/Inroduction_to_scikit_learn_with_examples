{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our supervised models, we have far more choice than just using the train_test_split function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a method of evaluating generalization performance that\n",
    "is more stable and thorough than using a split into a training and a test set. In crossvalidation,\n",
    "the data is instead split repeatedly and multiple models are trained. For example, when performing five-fold cross-validation,\n",
    "the data is first partitioned into five parts, called folds.\n",
    "Next, a sequence of models is trained. The first model is trained using the first fold as\n",
    "the test set, and the remaining folds as the training set. The model is\n",
    "built using the data in folds 2–5, and then the accuracy is evaluated on fold 1. This is repeated for all the other folds.\n",
    "For each of these five splits of the data into training and test sets, we compute the\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is implemented in scikit-learn using the cross_val_score function\n",
    "from the model_selection module. The parameters of the cross_val_score\n",
    "function are the model we want to evaluate, the training data, and the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s evaluate LogisticRegression classification model on the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mean cross-validation we can conclude that we expect the model to be\n",
    "around 97% accurate on average. Looking at all five scores produced by the five-fold\n",
    "cross-validation, we can also conclude that there is a relatively high variance in the\n",
    "accuracy between folds, ranging from 100% accuracy to 93% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is especially useful when we don't have enough data to get a decent test set. Also the range of the accuracies returned can give us some kind of idea about the worst and best case secenario for the accuracy the model can handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our iris dataset looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris labels:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(\"Iris labels:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the standard cross validation, then the first fifth of the data will be used for test and therefore our test data will only be made up of examples of only one class and so on for the other folds. This will lead to some reallly bad accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, scikit-learn automatically uses stratified k-fold cross validation for classification case, this means it choses examples for each set that is propotional to the whole dataset. sciki-learn, however, only uses the standard cross validation for the regression case as it is akward and does not mak too mach to stratify regression labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More control over cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adjust the number of folds that are used in\n",
    "cross_val_score using the cv parameter. However, scikit-learn allows for much\n",
    "finer control over what happens during the splitting of the data by providing a crossvalidation\n",
    "splitter as the cv parameter. For most use cases, the defaults of k-fold crossvalidation\n",
    "for regression and stratified k-fold for classification work well, but there\n",
    "are some cases where you might want to use a different strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we may not want scikit-learn to automatically use the startified k-cross validation and we want to use the standard one only. Then, we import the KFold splitter class from the model_selection module and instantiate it with the number of folds we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can pass the kfold splitter object as the cv parameter to cross_val_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[1.         1.         0.86666667 0.93333333 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can randomize the order of the data points by setting the shuffle parameter of KFold to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of leave-one-out cross-validation as k-fold cross-validation where each fold is a single sample. \n",
    "For each split, you pick a single data point to be the test set. This can be very\n",
    "time consuming though, particularly for large datasets but can give us better evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iterations:  150\n",
      "Mean accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "\n",
    "print(\"Number of cv iterations: \", len(scores))\n",
    "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle-split cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In shuffle-split cross-validation, each split samples a specified number of points for the\n",
    "training set and the test set. This splitting is repeated a specified number of times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing to note is that, the size of training set and test set combined need not add to the whole dataest as in other techniques. For example, we can only use 50% od data for training and 20% of data for test at each iteration and leave the rest of the 30% alone. This is especially hepful for very large datasets where we want to save some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.94666667 0.96       0.96       0.96       0.97333333 0.94666667\n",
      " 0.96       0.97333333 0.97333333 0.97333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stratified version is in StratifiedShuffleSplit, which is better suited for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very common setting for cross-validation is when there are groups in the\n",
    "data that are highly related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, you want to build a model that recognizes images from an image. The problem arises when more likely or not you will have a lot of images a few people. Therefore, when you split the data for validation, some pictures of a person will be in the training set but some will also be in the test set. So, the model would give high accuracy \"falsely\" as it may have just memorized the features of that person. What you really want is to set the model on image of people it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common application is in medicine, where you\n",
    "might have multiple samples from the same patient, but are interested in generalizing\n",
    "to new patients. Similarly, in speech recognition, you might have multiple recordings\n",
    "of the same speaker in your dataset, but are interested in recognizing speech of new\n",
    "speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, we can use GroupKFold, which takes an array of groups as argument\n",
    "that we can use to indicate which person is in the image. The groups array here indicates\n",
    "the group the corresponding data (at that index) belongs to. The size of the groups array will be the same size as the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.75       0.6        0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rada_\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass groups=[0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "# Create synthetic dataset of size 12\n",
    "X, y = make_blobs(n_samples=12, random_state=0)\n",
    "\n",
    "# Assume the first three samples belong to the same group, then the next four, etc.\n",
    "groups = [0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3]\n",
    "\n",
    "scores = cross_val_score(logreg, X, y, groups, cv=GroupKFold(n_splits=3))\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the Error message, this was just fake synthetic data for illustration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are even more cross-validation techniques implemented in scikit-learn but the ones mentioned above are the most commonly used ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
